%
%		AFIT THESIS MACRO PACKAGE DOCUMENTATION
%                      for version 2.7 of afthesis.cls
%
%
% This file shows the directions of preparing your thesis using the 
% `afthesis' LaTeX document class. This class is an extremely modifed
% `report' document class with new commands added and some old
% commands modified to produce the proper format for the Air Force 
% Institute of Technology thesis or dissertation.
%
% To keep everything simple, this file is designed so that you can use a
% a copy of this file as your LaTeX input file after replacing the
% necessary data by your own data, and inserting your text in the proper
% positions. Inserting text can be done by:
%	-- actually typing the text, or
%	-- using LaTeX \input or \include command
% in the designated position.
% Note that your LaTeX input file name should have the .tex extension, 
% as are the files to be \input'd or \include'd.
%
% The commands \input{foo} inside mythesis.tex will have the effect as 
% if the contents of foo.tex is inserted in the position where the 
% \input command is encountered. To run LaTeX, use the 
% command
%
%	latex mythesis 
%
% To be able to write the inserted text correctly, you are supposed to 
% know basic LaTeX.  All you need to know about LaTeX is written in 
% Leslie Lamport's
% `LaTeX: A Document Preparation System' (Addison-Wesley 1986), which is
% available in local bookstores. 

\documentclass[11pt]{afthesis}
\usepackage{amsmath}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{amsfonts}

%\documentclass[10pt]{afthesis}  %if you want 10pt instead of 11
%\documentclass[12pt]{afthesis}  %if you want 12pt instead of 11


%\dissertation   % print DISSERTATION instead of THESIS on the title

% Number by chapter ?
%
% You may specify the numbering in your thesis/dissertation to be 
% chapter numbering instead of the default of sequential numbering.  
% If you select this option you will get pages, figures, tables, and 
% equations numbered by chapter (e.g., Table 2.3, Figure 3.4, 
% page numbers 2-40, A-1)
% To not get chapter numbering add a `%' character to the beginning of 
% the next line 

\numberbychapter

% Print section numbers ?
%
% You may select not to have section (and subsection, etc.) numbers 
% printed in the text and in the table of contents. In fact this is 
% the way the AFIT thesis guide shows it, but I like section numbers 
% so I made having section numbers the default.
% To get no section numbers remove the `%' character in the beginning 
% of the next line

%\nosectionnumbers

% Type of empasis ?
%
% You may select to have your emphasized text (like chapter and section
% headings, book titles, foreign phrases, etc.) underlined instead of
% set in an italic font.  By selecting this option, appropriate titles
% are automatically changed, plus anytime you use the command {\em ...}
% you will get underlined text, instead of italic text.  NOTE: this 
% option is not recommended for typeset quality documents. It is here 
% only for those who are old fashioned, type-writer personalities.
% To get underlining instead of italics remove the `%' character in the
% beginning of the next line

%\underlineoption

% Flyleaf frame ?
% 
% You can select to have a 4in by 2in frame put around your flyleaf 
% material.  This makes it look a little nicer if you don't have the 
% cover with the hole in it.
% To get a flyleaf frame remove the `%' character in the beginning of
% the next line.

%\flyleafframe

% Line spacing
%
% The default line spacing is to doublespace except in quotations, 
% quotes, and the bibliography.  This approximates the spacing you 
% get if you "doublespace" on a typewriter.  If you want to change 
% the line spacing use the command \spacing{n} where n is a real 
% number at the start of the document and \endspacing at the end 
% of the document. Use 1 for n to get singlespacing, 1.5 for space 
% and a half, etc.  If you want to change the linespacing to 
% singlespace for a particular section of text, you can use the 
% singlespace environment bracketting your text with 
% \begin{singlespace} and  \end{singlespace} \spacing{2} is the 
% default line spacing for the thesis in 10pt \spacing{1.5} is the 
% default line spacing for the thesis in 11pt and 12pt
%
%  THE ABOVE LINE SPACING INFORMATION IS NOT QUITE ACCURATE
%
% Data of author and thesis: The following data will be used throughout
% your thesis when they are needed. Please replace the dots in the
% commands by your own data. For some commands, the specified default
% value will be assumed when the command is omitted.  For a two author
% thesis, specify the command \twoauthor and then enter the appropriate
% additional fields.  Remember you will need two vitas specified in
% author order.  Authors should be specfied in alphabetical order.

\author{Justin Fletcher}


\rank{First Lieutenant, USAF}

\title{ANISOTROPIC SIMULATED ANNEALING AND ITS APPLICATION TO FEED FORWARD NEURAL NETWORK WEIGHT SELECTION}

%\flytitle{...}
%
% Remove the % and replace the dots in the above command with your
% thesis title as it should be on the flyleaf.  This is only needed
% if your flyleaf title has different line breaks 
% (because it must fit in 4 inches)
% than the way it appears on the title page and on the first page.

\designator{AFIT/GE/ENG/16-..}
%
% Replace the dots in the above command with the thesis or dissertation
% designator. For example, `AFIT/GCS/ENG/87-5'.

%\distribution{...}
%
% Replace the dots in the above command with the distribution
% statement for your thesis.  The default if commented out is 
% `Approved for public release; distribution unlimited'.

\previousdegrees{B.S. CEC}
%\previousdegreestwo{...} %uncomment for twoauthor option
%
% Replace the dots in the above command with the 
% abbreviated form of your previous degree(s), e.g., B.S. or B.A., M.S.
% Leave this command out if you have no previous degrees.

\degree{Master of Science in Computer Science}
%
% The degree sought as determined by your program. 
% For example, `\degree{Master of Science}', or
% `\degree{Master of Science in Electrical Engineering}'.
% The default value is `Doctor of Philosophy' for dissertation.

\graduationdate{June, 2016}
%
% Replace the dots in the above command with the 
% graduation date, in the form as `\graduationdate{May, 1986}'.
% The default value is guessed according to the time of running LaTeX.

\address{452 Orchard Drive\\Oakwood, Ohio 45419}
%\addresstwo{...\\...} %uncomment for twoauthor option
%
% Replace the dots in the above command with your permanent address.
% Use \\ to separate address lines.  This is used in the Vita.
% e.g., `\address{4533 Avenue A\\ Austin, Texas 78751}'.

\school{Electrical and Computer Engineering}
%
% Replace the dots in the above command with the name of your school.  
% For example, `\school{School of Engineering}'

%**********for dissertations only, remove the % signs and add the data
%\dean{...}
% Needed for disserations only.
% The name of your dean, e.g., `\dean{Robert A. Calico, Jr}

\committee{Dr. Michael J. Mendenhall\\Thesis Advisor,
	Dr. Gilbert L. Peterson\\Committee Member,
	Capt. Charlton D. Lewis, Ph.D.\\Committee Member}
% 
% The default value is 5 for dissertation. 

\begin{document}
	
	% The following commands will automatically generate headings, adjust
	% vertical spacings, break pages, etc.
	% You should probably leave all of these prefatory pages commented out
	% or in a \include file until your thesis is ready for final draft
	
	\flyleaf      			% Generates the flyleaf.
	
	\disclaimerpage                 % Produces the disclaimer page
	
	\titlepage			% Produces the title page.
	
	\approvalpage                   % Produces the approvalpage
	
	\begin{preface}
		%
		%Insert the text of your preface here. Your name will appear
		%automatically. If this is an acknowledgments section instead of 
		%preface, use \begin{acknowledgments} and \end{acknowledgments}
		% instead.
		%
	\end{preface}
	
	\tableofcontents	% Table of Contents will be automatically
	% generated and placed here.
	
	\listoffigures  	% List of Figures, List of Tables, and List of
	\listoftables		% Symbols will be placed here, if applicable.
	\listofsymbols      % Do not use these if you have no such lists.
	% To put symbols in the list use command \symbol[#1]{#2}
	% where #2 is the symbol and #1 is the definition to be put in the
	% list of symbols. The symbol is also automatically put in
	% your text.  Leave out [#1] if you don't want a definition.
	
	\listofabbreviations
	
	\abbreviation[Artificial Neural Network]{ANN}
	% similar to the list of symbols.  Use command \abbreviation[#1]{#2}
	% where #2 is the abbreviation and #1 is the definition to be put in the
	% list of abbreviations. The abbreviation is also automatically put in
	% your text.  Leave out [#1] if you don't want a definition.
	
	\begin{abstract}
		% Lower-end page count: 131
		% Upper-end page count: 170
		% DO: Write abstract.	
		Stub.
	\end{abstract}
	
	
	\chapter{Introduction}
	
	% DO: Write introduction.	
	% The first chapter. \chapter command is of the form \chapter[..]{..} or \chapter{..} where {chapter heading} and [entry in table of contents].
	
	% Do this after the thesis is written. I created an algorithm which simulates quantum tunneling through an error manifold. I applied this algorithm to the problem of selecting weight values for a neural network. It works well for small data sets, but is slower when dimensionality of the data set on which the network is trained is very large. 
	
	
	Stub.
	
	% In chapter three the traversal a error manifold in the problem configuration space is discussed at length. Several traversal methodologies are proposed and evaluated. 
	
	
	% Important: If your chapter heading consists of more than one lines, it will be automatically broken into separate lines. However, if you don't like the way LaTeX breaks the chapter heading into lines, use `\newheadline' command to break lines. NEVER USE \\ IN SECTIONAL (E.G., CHAPTER, SECTION, SUBSECTION) HEADINGS!!!!!!!!
	
	\chapter{Background} % This is Chapter 2.
	
	This chapter serves as a comprehensive review of the physical and computational concepts material to the topic of this thesis. A broad overview of artificial neural networks and the application and history thereof is presented. Next, various formulations of simulated annealing are described, along with a summary of some related works and a description of the physical inspiration for the algorithm. The chapter concludes with a very brief overview of the quantum mechanics, with emphasis placed on those concepts which will be employed throughout the document. Finally, the notation and terminology conventions adopted in this thesis are established.
	
	\section{Artificial Neural Networks}
	
	% Is there a better term than sequential computing machinery? 
	
	% Each word in this name encodes a significant concept related to the origins and structure of the models: neural is a reference to neurons, which are the fundamental information processing elements of the biological systems which inspired the model; network refers to network theory, a subfield of graph theory, which governs representation of relationships between neurons; and artificial, meaning an object of human origin, in contrast with biological neural networks which arise naturally.
	
	It has long been recognized that the capacity of biological information processing systems to flexibly and quickly process large quantities of data greatly exceeds that of sequential computing machinery. This information processing capability arises from the complex, nonlinear, parallel nature of biological information processors. The family of models designed to replicate this powerful information processing architecture are collectively called artificial neural networks (ANNs). In the most general sense, ANNs are parallel distributed information processors \cite{haykin1999} comprising many simple processing elements. Networks store information about experienced stimuli in the form of connection strengths and network topology and can make that information available. In such a network, interneuron connection strengths are used to encode information, and are modified via a learning strategy. ANNs are characterized by three features: a network topology or architecture, an activation function, and a learning strategy; each is discussed in the following sections. Additionally, an abbreviated history of ANNs is provided and the biological inspiration for the computational model is described.
	
	\subsection{Biological Inspiration}
	
	This is all one big stub.
	
	Fig[an image of a neuron, mapped to a schematic of a neuron, mapped to a processing element]
	
	Integration of magnitude-encoded, rather than frequency-encoded, signals. 
	Threshold functions relationship to the biological shape, size... Papers needed.
	
	Biological neural networks are many orders of magnitude slower than those based in ... It in not the size of the network or the number of interconnections alone which confer upon the human brain its remarkable efficiency (Faggin, 1991). Though size and connectivity are necessary, it is the structure, or topology of the network of interconnections that en
	
	% What is the physical mechanism for synaptic depression? Flooding of synaptic cleft with inhibitory neurotransmiters?
	
	Activation time-line: The concentration of neurotransmitters in the extra-synaptic fluid increases, raising the instantaneous membrane potentiality, possibly breaching the threshold potential causing a fire-and-reset, where the there is some physical limit on the rate at which the reset step can occur, thus causing the diminishing response seen in Figure 2 of Neurocomputing, whence the fire causes either excitatory or depressive neurotransmitters to be released at the synaptic clefts formed at the end of the axon, thus propagating the activation through the net.
	
	What is changed in synaptic modification is the efficiency with which a particular post-synaptic site is able to convert neurotransmitters in the surrounding intercellular environment, which is to say in the synaptic cleft, into a change in charge inside the cell.
	
	Activation function: A neurons activation function is just a phenomenon emerges from from the combination of its potential threshold and rest rate, both of which are physiological properties which can change after cell formation. (Instructing Perisomatic Inhibition by Direct Lineage Reprogramming of Neocortical Projection Neurons, 2015)
	
	\subsection{Historical Overview}
	
	
	% Pre-1970
	The study of ANNs began with a 1943 paper \cite{mcculloch1988} by McCulloch and Pitts. In this paper, McCulloch and Pitts united, for the first time, neurophysiology and formal logic in a model of neural activity. This landmark paper marked the beginning of not only the computational theory of neural networks but also the computational theory of mind, and eventually led to the notion of finite atomata \cite{piccinini2006}. In  \cite{mcculloch1988} McCulloch and Pitts introduced a very simple model of a neuron, which acted as a threshold-based propositional logic unit. Significantly, McCulloch and Pitts showed that a network of their neuron models, interconnected, could represent a proposition of arbitrarily-high complexity. Said differently, a network of the neuron models described in  \cite{mcculloch1988} can represent any logical proposition. These models are often called McCulloch-Pitts neurons and permit only discrete input values which are summed and compared to a threshold value during a fixed time quantum, and do not posses any learning mechanism.  McCulloch-Pitts neurons are able to incorporate inhibitory action, but the action is absolute and inhibits the activation of the neuron without regard to any other considerations. The McCulloch-Pitts neuron model is of theoretical significance, but cannot be applied to practical problems.
	
	%[Graphic Stub: Simple McChulloch-Pitts neuron.]
	
	Though McCulloch and Pitts made mention of learning in their 1943 paper, thirteen years would pass before the learning concept was formalized into a mathematical and computational model. In 1956 Rochester, Holland et. al. \cite{rochester1956} presented the first attempt at using a physiologically-inspired learning rule to update the synaptic weights of a neural network. This model was based on the correlation learning rule postulated in 1949 by Hebb\footnote{It should be mentioned that, while Hebb was the first to postulate the correlation learning rule as it relates to neurons and synaptic connection strength, the abstract rule was foreshadowed as early as 1890 by William James \cite{james1890principles} in Chapter XVI of \textit{Psychology (Briefer Course)}.}. In his book \textit{The Organization of Behavior}, Hebb suggested that synaptic plasticity, that is the capacity of synaptic strengths to change, is driven by metabolic and structural changes in the both neurons near the synaptic cleft \cite{hebb1967} such that if two cells often fired simultaneously the efficiency with which they cause one another to fire will increase. This efficiency is now called a synaptic weight. Rochester et. al. showed that the addition of variable synaptic weights alone was not sufficient to produce a network capable of learning; the weights must also be capable of assuming inhibitory values.
	
	% DO: is this paragraph too detailed, or not detailed enough? 
	% DO: Quick graphic of the perceptron.
	
	[Graphic Stub: simple perceptron terminology, figure.]
	
	The next major contribution to the field would come in 1958 with Rosenblatt's introduction of the simple perceptron \cite{rosenblatt1958perceptron}. The perceptron was the first \cite{anderson1988neurocomputing} well formed, computationally oriented neural network. Crucially, and unlike most preceding neural models, the model Rosenblatt presented in his  1958 paper was associative. That is, the model learned to associate stimuli with a response. This learning is accomplished by modifying the synaptic weights of the model such that the difference between an input pattern and the desired output pattern is minimized. The responsibility for the error, or difference between the correct and computed output patterns, is divided among the weights in proportion to their magnitude. Thus, large synaptic weights will be reduced more than small synaptic weights for a large, positive error. This weight update strategy is represented mathematically as: \begin{equation} 
	w_i(t+1) = w_i(t) + \alpha(d_j - y_j)x_{j,i}
	\end{equation} where \begin{math} w_i(t) \end{math} the synaptic weight for feature \begin{math} i \end{math} at discrete time \begin{math} t \end{math}, \begin{math} \alpha \end{math} is the tunable learning rate parameter, \begin{math} d_j \end{math} is the desired output, \begin{math} y_j \end{math} is the computed output, and \begin{math} x_{j,i} \end{math} is the input pattern. This method constitutes a from of reinforcement learning.
	
	
	Rosenblatt's perceptron was found to be successful at predicting the correct response class for stimuli only if the responses were correlated. It was not until Block's 1962 publication that the reason for this observed performance was elucidated. In this paper, Block presented two key findings: first, that simple perceptrons require linearly separable classes to achieve perfect classification and second, the perceptron convergence theorem \cite{block1962perceptron}. Linear separability is the ability of the response classifications to be separated by a hyperplane in the \begin{math}n\end{math}-dimensional space of the input stimuli to which they correspond. The requirement of linear separability arises directly from the way in which the output of a perceptron response unit is calculated. The output of a perceptron response unit is given by:
	\begin{equation} 
	y_j = \begin{cases}
	-1 &\sum_{i=1}^{n} w_{i,j}x_{i} \leq \Theta\\
	+1 &\sum_{i=1}^{n} w_{i,j}x_{i} > \Theta
	\end{cases}
	\end{equation} where \begin{math} y_j \end{math} is the response value of response unit \begin{math} j \end{math}, \begin{math} w_{i,j} \end{math} is the synaptic weight of the connection between activation unit \begin{math} i \end{math} and response unit \begin{math} j \end{math}, \begin{math} x_{i} \end{math} is the activation value of activation unit \begin{math} i \end{math}, and \begin{math} \Theta \end{math} is the threshold value of the perceptron. Block's crucial observation was that the form of the summation in the response determining equation is isomorphic to a hyperplane in an \begin{math}n\end{math}-dimensional space. Thus, in order for the perceptron to achieve perfect classification, a hyperplane must be able to separate them in the \begin{math}n\end{math}-dimensional input space. The corollary of this observation it the perceptron convergence theorem. The theorem proves that for some learning rules, if a perfect classification is possible it will be found by the perceptron. Specifically, the class of learning rules which were found effective were those which did not change synaptic weights when a correct classification occurs. While the condition does ensure convergence, it often causes very slow convergence, as the synaptic weights change much more slowly when only a small number of samples remain misclassified. Considerably faster guaranteed convergence can be achieved using a error gradient descent learning rule \cite{widrow1960asc}, as described by Widrow and Hoff. 
	
	
	In 1969 Minksy and Papert published \textit{Perceptrons}, a book on mathematics and theory of computation. In this book Minsky and Papert mathematically and geometrically analyzed the limitations inherent in the perceptron model of computation. The authors reasoned that the each response unit of Rosenblatt's perceptrons was actually computing logical predicates about the inputs it received, based on the observation that response units can either be active or inactive. This analytical framework allowed the authors to construct unprecedented geometric and logical arguments about the computational capabilities of a perceptron. They found that there were several classes of problems which were unsolvable by linear perceptrons \cite{minsky1969perceptrons}. In the final chapter of the \textit{Perceptrons} Minsky and Papert extended their judgments regarding the ineffectiveness of single-layered perceptrons to all variants of perceptrons, including the multi-layered variety. This conjecture would turn out to be one of the most significant of the entire book, as it likely resulted in a reduction of funding for neural network research \cite{anderson1988neurocomputing} which lasted for several years. Unfortunately, this judgment was incorrect.
	
	% 1970-1980
	While it is true that the pace of development in the field of neural networks slowed considerably after the publication of \textit{Perceptrons}, there was still progress made during the 1970s. In 1972, both Anderson \cite{anderson1972interactive} and Kohonen \cite{kohonen1972correlation} published models of what would come to be known as linear associative neural networks, which are a generalization of Rosenblatt's perceptron. As with the perceptron, neurons in a linear associative neural network compute their output by summing the product of each input signal the synaptic weight associated with that input. Unlike the perceptron, the output of these networks is proportional to this sum, rather than a binary value computed by applying a threshold function to the sum. Though still unable to achieve perfect classification on many classes of problems, these networks were able to successfully associate input patterns with output patterns. 
	
	
	The decade also saw the advent of self-organized maps, which are a type of competitive learning neural network. Self-organization in neural networks was first demonstrated by van der Malsburg in a paper \cite{vonderMalsburg1973selforganization} published in 1973. This paper analyzed the response of simulated cortical cells to a simulated visual stimulus. The paper is interesting both for the complexity of the neural model developed, and because it contained the first direct comparison between computer simulation and physiological data \cite{anderson1988neurocomputing}. 
	
	% DO: I'm not exactly sure  how to handle this data. It seems to contradict the claim of the essenital nonlinear nature of neural nets.
	Throughout the decade progress was also made in the understanding of the physiology of biological neural networks. Of particular interest are those papers describing the lateral retinal system of \textit{Limulus polyphemus}, the horseshoe crab. Chosen for the easy with which experiments may be conducted on its compound lateral eye, \textit{Limulus} features prominently in the neurophysiological research. Several works were published on the \textit{Limulus}, perhaps the most significant of which came near the end of the decade with the 1978 publication of a paper describing the dynamics of the retina of a \textit{Limulus} when exposed to moving stimuli. In this paper,  the \textit{Limulus} eye was analyzed as a linear system, and the results of this analysis were compared to the actual response of the system to input pattern. The agreement between the linear\footnote{Linear, in this context of this system, means that the output of the system when presented with the sum of a set of inputs is equivalent to the sum of the outputs of the system when presented with each input individually.} model and the biological output signals was found to be in excellent agreement \cite{brodie78limulus}. This finding was interesting for the purposes of perceptron simulation, but was ultimately found not not to hold for larger collections of neurons. %(NEED SOURCE...)
	% post-1980
	
	%"Likelyhood of escpae graph"
	%"Relative likelyhood of escape graph"
	%"Projection from color on the PES to an independent graph"
	%"learn rate on PES with simulated annealing is just like downsampling the sapce and searching the downsampled space. Add stochat"
	% Simultaneously anneal topology, weights, and activation functions. How do you define distance in this configuration space which includes both discretes and reals?
	
	Several events conspired to create a reinvigoration of neural network research in the early 1980s. Theoretical advances in the physiology of biological neural networks. processor manufacturing technology had advanced sufficiently to allow for much larger-scale simulations.  simulation capability...
	
	In 1982, John Hopfield published \textit{Neural networks and physical systems with emergent collective computational abilities}. This momentous work is regarded by many to be the beginning of the renaissance of neural network research \cite{anderson1988neurocomputing}, and contains many novel insights. Hopfield begins the paper differently than past researchers. Rather than proposing a learning rule or network topology and then evaluating the results of this proposition, Hopfield begins by considering an alternative purpose for a neural network. Hopfield suggests that the network be thought of as a means to develop locally stable points, or attractors, in a state space. The state space comprises the set of states which are the activation value of each neuron. Thus, learning should be the process of modifying the synaptic weights such that they cause the system to flow into local attractors which represent the desired output. In such a model, a noisy or incomplete input would result in an activation pattern which resides on a gradient in the state space. The neural network would then change the activation pattern in such a way as to move the system down the gradient into the attractor state. Hopfield suggests that this process is a general physical description of the concept of content-addressable memory.
	
	% DO: Produce, in Julia, a 2d 2-minima plot.
	[Graphic Stub: notional activation state space with letters and noisy letters as points.]
	
	Hopfield then proposes a network architecture to achieve this behavior \cite{hopfield1982neuralnetworks}. The chosen model is one which has binary neural output values and recurrent connections. Neural networks of this types are now called Hopfield networks. Like Rosenblatt's original perceptron model, the neurons used in Hopfield's work had a non-linear, threshold activation function. The network topology was recurrent, with the restriction that no neuron could provide input to itself. Hopfield adopted a variation of Hebb's learning rule to update the synaptic weights.
	
	In Hopfield's network model, the connection strength between two neurons \begin{math}i\end{math} and  \begin{math}j\end{math} is denoted as \begin{math}T_{ij}\end{math}, and the activation status of a neuron \begin{math}i\end{math} is denoted as  \begin{math}V_i\end{math}. \begin{math}T\end{math} is therefore the connection matrix of the neural network, with each element representing an individual connection strength and zeros along the diagonal. It is from this organization of the connection strengths that one of the most important insights of this work originates. Hopfield recognized that, in the special case of the model in which \begin{math}T_{ij}=T_{ji}\end{math}, a quantity \begin{math}E\end{math} could be defined such that \begin{equation} 
	E= -\frac{1}{2} \mathop{\sum\sum}\limits_{i \neq j} T_{ij} V_i V_j .
	\end{equation} The change in this quantity as a result of a change in one of the activation values, \begin{math}V_i\end{math} in the following equation, is then represented as \begin{equation} 
	\Delta E= -\Delta V_i  \sum\limits_{j \neq i} T_{ij} V_j .
	\end{equation} From this equation, it is clear that any change in \begin{math}V_i\end{math} will reduce the value  of \begin{math}E\end{math}. This decrease in \begin{math}E\end{math} must necessarily continue until some local minimum of the value of \begin{math}E\end{math} is reached\footnote{An identical conclusion would be reached if \begin{math}V_j\end{math} was changed instead of  \begin{math}V_i\end{math}. It is merely a matter of convention.}. Here, Hopfield observed that this case is isomorphic with an Ising model," referencing the statistical mechanical model of magnetic spins. In this isomorphism, the quantity \begin{math}E\end{math} maps to the energy of a physical system described by an Ising model. It is difficult to overstate the importance of this observation. It both provided a novel mechanism by which physical theory could be applied to neural networks, and legitimized the study of neural networks as a physical system, encouraging many physicist to join in the development of the theory.
	
	Hopfield constructed a model of the system described in the paper, and presented it with random input patterns\footnote{Hopfield calls these input patterns entities or \textit{Gestalts}.}. He found that the network can indeed recall a small number of patterns, on the order of approximately 15 percent of the network dimensionality, before the recall error becomes significant.
	
	In 1985, Ackley et. al. extended the neural network model proposed by Hopfield\footnote{Though a Hopfield network was used for the work done by Ackley, Hinton, and Sejnowski it is not necessary to use network with recurrent connections.}. Hopfield networks are deterministic with respect to energy; by definition any change in a Hopfield network always reduces the energy of the system or leaves it the same. This is a useful property if it is acceptable to find one of many local minima, or attractors. However, if a single, global minima in the state space is sought this model is likely to converge prematurely to a local attractor state. In order to surmount this limitation Ackley et. al. modified the Hopfield neural model to activate stochastically. The probability of state transition, \begin{math}p\end{math}, is given by \begin{equation} \label{eq:boltzmannProb}
	p= \frac{1}{1 + e^{- \Delta E  / T} }
	\end{equation} where \begin{math} \Delta E \end{math} is the change in energy of the system resulting from a transition to a new state and \begin{math}T\end{math} is the artificial temperature of the system. Thus the relative probability, \begin{math}P_{\alpha}/P_{\beta}\end{math} of moving to either of two arbitrary global states, \begin{math}\alpha\end{math} and \begin{math}\beta\end{math}, is defined as \begin{equation} \label{eq:boltzmannDist}
	\frac{P_{\alpha}}{P_{\beta}} =  e^{- (E_{\alpha} - E_{\beta} ) / T} 
	\end{equation} which is a form isomorphic to the Boltzmann distribution. Thus, a neural network with transition probabilities described by equation \ref{eq:boltzmannProb} is called a Boltzmann machine. The effect of probabilistic state transitions of this form is that state transitions from low energy states to higher energy states are possible, thereby allowing the system to escape local minima. 
	
	Inspection of equations \ref{eq:boltzmannProb} and \ref{eq:boltzmannDist} reveals that the probability of transition is determined by both \begin{math}\Delta E\end{math} and \begin{math}T\end{math}. A large value of \begin{math}\Delta E\end{math}, which corresponds to a large increase in total energy, will decrease the probability of transition. Conversely, a large value of \begin{math}T\end{math} will increase the probability of transition for any arbitrary value of \begin{math}\Delta E\end{math}. The systems artificial temperature therefore acts as a tuning mechanism for the exploration of the state space. A high temperature value will result greater exploration of the space state, but will result in less gradient descent and therefore may cause the system to depart the attractor basin of the global minimum. A low artificial temperature parameter may cause premature convergence. Ackley et. al. solved this tuning problem by recognizing a deep connection to another concept born of statistical mechanics: simulated annealing. Simulated annealing decreases the artificial temperature of a system slowly over the course of a simulation, and as a result increases the likelihood that the final state of the system will be the ground state, which is to say the global minimum. This algorithm is discussed in detail in section \ref{eq:simulatedAnnealing}.
	
	% DO: Could use a better source here
	With a procedure for finding the global minimum of a space state in place, the authors proceeded to construct state spaces for which the global minimum was of interest. One way to construct such a state space is to include hidden units in the neural network. Hidden units are neural units which are neither input nor output units. These hidden units allow the network to solve interesting problems that are out of reach of simple associative neural networks\cite{anderson1988neurocomputing}. However, like all neurons in any neural network, the connection weights of these neurons must be modified in order for the network to learn. It is not immediately clear how hidden unit synaptic weights can be modified to account for the performance of the network. This deficiency is often called the credit assignment problem\cite{barto1983neuronlike}. The application of simulated annealing in Boltzmann machines avoids the problem of assigning credit to hidden units, thereby enabling their inclusion in the model. This is historically significant because it was the first successfully-implemented multi-layered neural network \cite{haykin1999}.

	The next major development in neural networks came in 1986 with the introduction of the back-propagation algorithm. Though the formalisms required involved in this algorithm had been developed earlier \cite{bryson1969optimalcontrol} \cite{werbos1974beyondregression}, and the method was simultaneously discovered independently by two other groups \cite{parker1985logic} \cite{lecun1985}, it was Rumelhart et. al. that applied the algorithm to machine learning \cite{rumelhart1986internal}. Back-propagation can be thought of as a generalization of the gradient descent\footnote{The gradient descended in this context is the gradient of the error surface in the space of states of synaptic weights, not the gradient of the activation state surface, as with a Hopfield network.} algorithm presented by Widrow and Hoff \cite{widrow1960asc}, which includes the errors associated with connection strength of hidden units, or internal representation units. A detailed discussion and derivation of the back-propagation algorithm is included in Section \ref{sec:backpropTraining}. Though back-propagation in multilayered perceptrons cannot be guaranteed to find an exactly correct solution, the algorithm is demonstrably capable of solving difficult and interesting problems, thus disproving the speculation of Minsky and Papert in \cite{minsky1969perceptrons}.
	
	% ...The utility of back propigation lies in its relative computational effeciency; though both back-propigation and simulated annealing can be used to select the synaptic weights for a neural network, back-propigation generally converges to a solution several orders of magnitude faster ()
	
	With the advent of Boltzmann machines and back-propagation, it became possible to analyze the properties and capabilities of multilayered neural networks. In 1989 Cybenko showed that a multilayer feedforward neural network with nonlinear activation function is in principle capable of approximating any continuous function  \cite{cybenko1989approxsuperposition}. This finding is striking because it implies that, given the correct learning rule and a sufficiently large network, a multilayer neural network can learn a pattern of arbitrary complexity. 
	
	
	%This, in turn, implies that neural networks can serve as universal function approximaters. (Cybenko1989)
	
	%(Kurt Hornik (1991) "Approximation Capabilities of Multilayer Feedforward Networks", Neural Networks, 4(2), 251–257)
	
	
	
	
	
	\subsection{Network Topology}
	
	Stub.
	
	%The topology of a neural network describes the way in which the individual processing units are interconnected. There are only a few broad classes of topology, each of which has different properties. 
%	Feed forward
%	recursive
%	recapitulated backprop here...
	\subsection{Activation Functions}
	
	Stub.
	% DO: Proof of the necessity of non-linearity.
	% DO: Any work on variable activation functions?
	
	\subsection{Learning Strategies}
	
	Stub.
	
	%General discussion.
	
	%Reference (Mendel and McClaren, 1970) and (Haykin, pg 50)
	
	
	\subsubsection{Back Propagation Training} \label{sec:backpropTraining}
	Stub.
	
	% DO: Consider pandimonium by slefedger
	
	% DO: Discuss (Rumelhart, Hinton, Williams, 1986)
	
	% DO: Derive back prop. (Haykin, pg 161)
	
	% DO: Discuss the implication of local minima.
	
	% DO: Fig[Error surface with backprop]
	
	
	\subsubsection{Simulated Annealing Training} 
	
	
	The first application of simulated annealing (SA) to the training of neural networks was accomplished by Engle in \cite{engel1988teachingfeedforwardnueralnetsbysa}, with limited success. Engle's work involved discrete
	
	% DO: Complete this section.
	
	
	\section{Related Works in Simulated Annealing} \label{eq:simulatedAnnealing}
	
	% DO: Read (Haykin pg 556)
	
	% DO: Read (Haykin pg 560)
	
	Simulated annealing is a stochastic optimization algorithm which can be used to find the global minimum of a cost function mapped from the configurations of a combinatorial optimization problem. The concept of simulated annealing was introduced in by Kirkpatrick et al. in \cite{kirkpatrick1983} as an application of the methods of statistical mechanics to the problem of discrete combinatorial optimization. Specifically, simulated annealing is an extension of the Metropolis-Hastings \cite{metropolis1953} algorithm which can be used to estimate the ground energy state of a many-body systems at thermal equilibrium. Kirkpatrick et al. applied the Metropolis-Hastings algorithm sequentially, with decreasing temperature values in order to approximate a solid slowly cooling to low temperatures. Later work by Goffe \cite{goffe1994globaloptimization}, Corana et al. \cite{corana1987minimizingmultimodal}, and Lecchini-Visintini et. al. \cite{lecchinivisintini2007sacontinuousgaruntees} extended SA to the continuous domain.
	
	In the most general terms, SA is a local search algorithm through the problems solution space, \begin{math} \boldsymbol{\mathcal{S}} \end{math}, which is the set of all possible solutions, \begin{math}\boldsymbol{s}  \end{math}, of the problem. The search is conducted by generating new solutions to the problem by applying a neighborhood function, \begin{math}\boldsymbol{\mathcal{N}} \end{math} to the current solution; the neighborhood function specifies the way in which a solution is transformed to yield a new solution, or neighbor solution, and is generally problem dependent. To apply SA to an optimization problem it must be possible to characterize each possible solution of the problem using a cost function, \begin{math}\mathcal{C} \end{math}, where \begin{math}\mathcal{C} \end{math} is the mapping
	
	\begin{equation*} \label{eq:cost_mapping}
	\mathcal{C} : \boldsymbol{\mathcal{S}} \rightarrow \mathbb{R}.
	\end{equation*}
	
	\noindent Because \begin{math} \mathcal{C} \end{math} is a function on \begin{math} \boldsymbol{\mathcal{S}} \end{math}, it is said that the cost function forms a cost surface in the solution space. During each iteration of the algorithm, a new solution, \begin{math}\boldsymbol{s}'  \end{math}, is generated using \begin{math}\boldsymbol{\mathcal{N}(\boldsymbol{s})} \end{math}, and the cost of that solution, \begin{math}\mathcal{C}(\boldsymbol{s}' ) \end{math}, is determined. The change in cost associated with moving from the current solution to the neighbor solution is given by 
	\begin{equation*} \label{eq:delta_cost}
	\Delta C =  \mathcal{C}(\boldsymbol{s}')-\mathcal{C}(\boldsymbol{s}).
	\end{equation*}
	
	\begin{math}\Delta C \end{math} is then used in conjunction with an artificial temperature parameter to determine if the newly-generated neighbor solution is to become the current solution. The artificial temperature parameter is specified by the temperature schedule, \begin{math}T(t)\end{math}, where \begin{math}t\end{math} is the number of simulation iterations completed. The temperature controls the probability of the system moving to a higher cost solution, thereby enabling the algorithm to escape local minima on the cost surface. In the parlance of SA \cite{kirkpatrick1983} a system at its maximum temperature is said to be \textit{melted}. In the melted state, most neighbor solutions are accepted by the algorithm. Analogously, a system that has a temperature of zero, which indicates that the algorithm cannot move to any higher-error state, is said to be \textit{frozen}. Note that a frozen system may still be perturbed into a lower-energy state. The notions of freezing and melting enter the SA algorithm in the form of the acceptance criterion, which determines if a newly-generated solution is to become the current solution. The most commonly used acceptance criterion is the Metropolis criterion \cite{metropolis1953}, given by:
	
	\begin{equation} 
	y_j = \begin{cases}
	1 &\Delta C   \leq 0 \\
	e^{-\frac{\Delta C}{T(t)}} & \Delta C > 0 
	\end{cases}
	\end{equation}

	
	The probability of moving to a solution which is higher in cost than the current solution is derived from the statistical mechanical probability of traversing a potential energy barrier by thermal fluctuations. When considering only the influence of classical thermal fluctuations in particle energy levels, the probability of a particle traversing a barrier of height \begin{math} \Delta V \end{math} at a temperature \begin{math} T \end{math} is on the order of \begin{equation} 
	\mathcal{P}_t = e^{-\frac{\Delta V}{T}} .
	\label{eq:thermal_traversal_prob}
	\end{equation}
	
	The SA algorithm is presented in Algorithm~\ref{alg:simulated_annealing}. 



	% The physical inspiration for simulated annealing. See (Haykin pg 546)
	
	\begin{algorithm}
		\caption{Simulated Annealing}
		\label{alg:simulated_annealing}
		\begin{algorithmic}
			\STATE $\boldsymbol{s} \leftarrow \boldsymbol{s}_0$
			\STATE $t \leftarrow 0$
			\WHILE{$T(t) > \epsilon$}
			\STATE $\boldsymbol{s}' \leftarrow \boldsymbol{\mathcal{N}}(\boldsymbol{s}) $
			\STATE $\Delta C \leftarrow (\mathcal{C}(\boldsymbol{s}')-\mathcal{C}(\boldsymbol{s}))$
			\IF{$\Delta C \leq 0 $}
			\STATE $\boldsymbol{s} \leftarrow \boldsymbol{s}'$
			\ELSE [$ \exp(\Delta C/T(t) ) > U\left( 0,1\right)  $]
			\STATE $\boldsymbol{s} \leftarrow \boldsymbol{s}'$
			\ENDIF
			\STATE $t \leftarrow t+1$
			\ENDWHILE
			\STATE $\boldsymbol{s}_{opt} \leftarrow \boldsymbol{s}$
			\RETURN $(\boldsymbol{s}_{opt})$
		\end{algorithmic}
	\end{algorithm}
		
	% DO: At least a paragraph on asymptotic convergence is required here.
	
	In \cite{szu1987fastsimulatedannealing} Szu and Hartley introduced the method of fast simulated annealing (FSA), which incorporates occasional, long jumps through the configuration space, These jumps are accomplished by using a heavy-tailed distribution, such as the Cauchy distribution, for the visiting distribution used in the neighborhood function. This provision increases the likelihood of escaping local minima, and reduces the total computational effort required to reach a global minimum. This modification yields a significant decrease in the amount of computation effort required to guarantee that a global minimum is found. Specifically, the FSA decreased the required temperature decay from $1/\ln(t)$ to $1/t$, where $t$ is the simulation time. 
	
	Later work by Tsallis and Stariolo \cite{tsallis1996generalizedsimulatedannealing}, generalized both CSA and FSA into a single framework: generalized simulated annealing (GSA). 
	 
	% DO: [discuss GSA here, and also SGSA and the many applications of GSA]
	
	% Be sure to include some discussion of thermal fluctuations and their importance. Find a nice source...
	\subsection{Reannealing}
	
	In \cite{ingber1989veryfastsimulatedreannealing}, Ingber introduced the concept of reannealing, which is a mechanism which allows for the artificial temperature parameter to be occasionally increased. The increase, or rescaling, of the temperature parameter enables the SA algorithm to move to higher cost solutions, effectively restarting the annealing process, but from a configuration space location that is already known to be a local minima. This mechanism allows the SA algorithm to escape from local minima, and thus decreases the simulation time required to avoid final convergence to a global minima.
	
	\section{Related Works in Quantum Mechanics}
	
	Quantum mechanics is the branch of physics concerned with the physical laws of nature at very small scales. Many aspects of physical reality are observable only at these scales. Several techniques described in this document are either inspired by, or are simple models of quantum mechanical processes. These concepts are very briefly reviewed in this section. 
	
	\subsection{Quantum Tunneling} 
	
	
	One of the quantum phenomena for which there is no classical analog is potential barrier penetration, also known as quantum tunneling. This phenomenon arises from the probabilistic and wavelike behavior of particles in quantum physics. Tunneling plays a significant role in the behavior of bound and scattering quantum mechanical systems.
	
	A particle with energy \begin{math} E \end{math} incident upon a potential energy barrier of height \begin{math} \Delta V > E  \end{math} has a non-zero probability of being found in, or past, the barrier. Classically, this behavior is forbidden. The probability of tunneling, \begin{math} \mathcal{P}_t \end{math}, through a step barrier of height \begin{math} \Delta V  \end{math} is described by: 
	\begin{equation}
	\mathcal{P}_t = e^{-\frac{w \sqrt{\Delta V}}{ \Gamma}} 
	\label{eq:quantum_tunneling_prob}
	\end{equation} where \begin{math} \Gamma \end{math} is the tunneling field strength \cite{mukherjee2015multivariatesearchqa}. Fig.~\ref{fig:quantum_tunneling} depicts a one-dimensional example of the quantum tunneling of the probability distribution function of the location of a particle indecent upon a potential energy barrier.
	
	\begin{figure}[ht!]
		
		\begin{center}
			\includegraphics[width = 3.2in]{figures/tunneling_ex.eps}
		\end{center}
		\caption{(Bottom) A simple step potential in one dimension. (Top) The probability density function of a generic quantum system in the presence of a potential energy step barrier. There is an exponential decrease in probability through the barrier, and a uniform probability beyond the barrier.}
		
		\label{fig:quantum_tunneling}
	\end{figure}
	
	%\subsection{Quantum Annealing}
	
	%Quantum annealing is the use of quantum, rather than thermal fluctuations to traverse the free energy landscape of a system. This is accomplished by introducing an additional Hamiltonian term that does not commute with the classical Hamiltonian. The term is introduced to account for the presence of a tunneling field which controls the frequency with which quantum fluctuations occur in the system. In effect, this term controls the relative importance of quantum effects on the behavior of the modeled system. This term, much like thermal energy in simulated annealing, is gradually reduced over the course of the simulation \cite{das2005qakcs}. The time dependent Schrödinger equation \footnote{Note that the presence of the Schrödinger equation in section does not imply that quantum annealing requires the annealed system must be an approximation to a wavefunction. It merely serves as an exposition of the properties of physical system which is modeled.} for such a system has the form \cite{mukherjee2015multivariatesearchqa}: \begin{equation}
	%[\lambda(t)H' + H_0]\psi = i\hbar \frac{\partial \psi}{\partial t}
	%\end{equation} where \begin{math} \lambda(t) \end{math} is the time-variance function of the tunneling field, \begin{math} H' \end{math} is the Hamiltonian term describing the tunneling field, and \begin{math} H_0 \end{math} is the classical Hamiltonian. 
	
	%The fluctuations induced by the tunneling field are tunneling events, which transition the system from one configuration to a different, lower-energy configuration directly, without assuming any of the higher energy configurations between the two. Said differently, the quantum tunneling field enables the penetration of energy barriers. The addition of these quantum fluctuations also ensures that each possible state of the system can be reached \cite{das2005qakcs}. 
	
	% Strictly speaking, this document does not claim to describe a quantum annealing process as it is presented in the referenced literature. 
	
	% There is a great deal of academic writing describing QA in the language of physics, but very little writing describing the concept from an algorithmic perspective. For this reason, and because there are significant differences between the artificial simulation of quantum-inspired annealing and the physical phenomenon which is being approximated, a new terminology is proposed. In this document, a new more specific term is introduced in order to disambiguate.
	
	% Simulated quantum annealing (SQA) is the quantum mechanical counterpart of simulated thermal annealing. Like simulated thermal annealing, simulated quantum annealing is a global search algorithm which seeks the global minimum of a cost function in a configuration space. 
	
	% In continuously oscliating annealing schedules, consistently good states will tend to attract the search. Bad states will be randomly visited. Partition the space of states into for each synapse into discrete bins. Track the number of times a bin is hit by the search for each synapse. Given enough time and suffiently small bins, the modes of each histogram will come to represent the global minima.
	
	
	\section{Notation and Terminology Conventions}
	
	There is a great deal of academic writing describing quantum annealing in the language of physics, but very little writing describing the concept from an algorithmic perspective. For this reason a new, more specific term is introduced in this document. Simulated quantum annealing (SQA) is the quantum mechanical counterpart of simulated thermal annealing. 
	
	% [Physics to Algorithmic translation table]
	% Free Energy Surface - Error Manifold - Cost Function
	% System Configuration -  
	
	The term neuron will be used in this document to describe the information processing elements of a neural network. This convention is selected both for conciseness and for the useful adjectival form, neural, which will be of great explanatory utility in the coming chapters.
	
	
	%Read (Haykin pg 561) Table 11.1
	
	
	\chapter{Methodology}
	
	The application of SA to feed-forward neural network weight selection requires the specification of several formalisms and representations linking the two concepts. In this chapter the representations adopted in this thesis are discussed. These representations will be combined into a set of formalisms which describe the various approaches to the application of SA to feed-forward neural network weight selection. A design of experiments, which will be used to evaluated the performance of these approaches, is established.
	
	\section{Simulated Annealing}
	\label{scn:simulated_annealing}
	
	In this thesis, several variations the SA algorithm are developed and implemented. Each is applied to the problem of selecting synaptic weights for a feed-forward neural network in order to maximize the networks classification performance. This section contains an abstract discussion of the SA formulations to be applied to this task; later sections will expound the implementation details specific to the feed-forward neural network application of the these SA formulations. For all SA formulations examined in this thesis the Metropolis acceptance criterion will be used. The temperature schedule will be determined by the convergence properties of the constructed algorithm. Examining Alg.~\ref{alg:simulated_annealing} reveals that the preceding specifications leave only one component unspecified: the neighborhood function, which determines how new trial solutions are generated form the current solution. In the following sections the neighborhood function is decomposed into two decoupled components, the visiting distribution and anisotropicity policy, and several possible realizations of each are discussed.
	
	\section{Neighborhood Functions: Traversing the Cost Surface}
	
	The SA algorithm requires that a neighborhood function, \begin{math} \mathcal{N} \end{math}, be specified to produce new solutions from a given solution. The neighborhood function performs the exploration of the solution space, as it specifies new solutions which can be either accepted or rejected according to the acceptance criteria. Thus, \begin{math} \mathcal{N} \end{math} determines how the algorithm traverses the cost surface of the problem. A traversal action, or move, on a surface, may be decomposed into two components: the distance moved and the direction of the move. These components may be specified independently of one another. The distance of the move on the cost surface has been examined in previous work \cite{szu1987fastsimulatedannealing,tsallis1996generalizedsimulatedannealing,ingber1989veryfastsimulatedreannealing}, and is often specified using a \textit{visiting distribution}, which is defined as a probability distribution of transition to a solution over the solution space of the problem. The visiting distribution specifies the magnitude and the direction of the move
	
	In previous work \cite{tsallis1996generalizedsimulatedannealing}, the move distance has been applied isotropically in all possible dimensions of travel. In physical science, isotropicity is phenomenological property of being uniformly applicable in all dimensions. In the context of neighborhood functions this means that the probability distribution over the solution space is symmetric; that is, that the probability distribution in each dimension is the same. In the following sections a method is developed for specifying an anisotropic visiting distribution.
	
	
	\subsection{Visiting Distributions}

	
	The visiting distribution of a neighborhood function is probability density function over all possible solution states, which gives the probability of transitioning from the current state of the system to each other state. Once a visiting distribution is specified, samples can be drawn from the distribution using inverse transform sampling. These samples may be either drawn from an $n$-dimensional distribution, where $n$ is the number of free parameters of the problem, or $n$ samples can be drawn and applied to each of the free parameters independently. In this thesis, all visiting distributions are implemented using the latter method. In the following sections several visiting distributions will be discussed.
	
	\label{scn:visiting_distributions}
	
	\subsubsection{Gaussian Visiting Distributions}
	\label{scn:classical_visiting}
	
	A Gaussian visiting distribution is commonly used in SA. Because it is a light-tailed distribution, and therefore indicates very low probability for all values far from the mean, Gaussian visiting distribution results in a search which is highly local about the mean. The mean of the visiting distribution is always the current solution location in solution space of the SA algorithm. An SA algorithm using a Gaussian visiting distribution is often called classical simulated annealing (CSA) \cite{tsallis1996generalizedsimulatedannealing}, both because it is the formulation of SA that was described first, and because the dynamics of the algorithm are isomorphic with those of classical thermodynamics. In this work, a standard normal distribution is used. The probability density function for this distribution is given by 
	\begin{equation}
	g_G(x) = \frac{e^{-\frac{1}{2} x^2}}{\sqrt{2\pi}}.
	\label{eq:normal_pdf}
	\end{equation}
	
	\subsubsection{Cauchy Visiting Distributions}
	\label{visiting_distribution_abstract_cauchy}
	
	Local search must occur in order to enable gradient descent, but it introduces a limitation. If the artificial temperature, which controls the probability of moving uphill on the cost surface, is lowered too quickly the algorithm can be caught in a local, rather than global, minima; this is also known as the freezing problem. One way to alleviate this limitation is to construct a neighborhood function which enables the system to escape local minima by means other than hill-climbing. In quantum mechanics, a system which is trapped in a local minimum on a potential energy surface may escape that minima by tunneling through the potential energy surface to a lower energy state. It is possible to construct several visiting distributions which act analogously to quantum tunneling. This can be done by using a visiting distribution that has a non-negligible probability of generating large traversal distances. If the traversal distances generated are sufficiently large, it is possible that the arrived-at solution will be across the cost surface barrier surrounding the local minima, thus allowing the algorithm to escape the minima. The term \textit{quantum-inspired visiting distribution} will be used in this thesis to describe any distribution possessing this property.
	
	\begin{figure}[ht!]
		
		\begin{minipage}[b]{0.48\linewidth}
			\centering
			\centerline{\epsfig{figure=figures/quantum_advantage_a.eps,width=7cm}}
			%  \vspace{2.0cm}
			\centerline{(a)}\medskip
		\end{minipage}
		\hfill
		\begin{minipage}[b]{0.48\linewidth}
			\centering
			\centerline{\epsfig{figure=figures/quantum_advantage_b.eps,width=7cm}}
			%  \vspace{2.0cm}
			\centerline{(b)}\medskip
		\end{minipage}
		%\vspace{-0.5cm}
		\caption{
			(a) A potential energy barrier on a one-dimensional potential energy surface.
			(b) The tunneling probability relative to the probability of traversal due to thermal fluctuation for a step barrier plotted as a function of the height and width of the barrier.}
		\label{fig:quantum_advantage}
		%
	\end{figure}
		
	 The significant performance gains exhibited by the FSA algorithm are the result of using a quantum-inspired visiting distribution. In \cite{szu1987fastsimulatedannealing}, which introduces the FSA algorithm, a Cauchy distribution is used to generate new solutions. Unlike the Gaussian distribution, the Cauchy distribution is heavy-tailed, meaning that it will occasionally produce values which are relatively far from the mean.  This property of the distribution has the useful consequence of increasing the probability of escaping a local minima by allowing the algorithm to tunnel through the cost-surface barriers that surround it. This in turn allows for faster convergence relative to CSA. To understand the origin of this advantage, it is instructive to contrast equations \ref{eq:thermal_traversal_prob} and \ref{eq:quantum_tunneling_prob}. Both describe the same value, but the importance of the width and height of the traversed barrier in the two equations is considerably different. For systems in which quantum tunneling is possible, the probability of penetrating a barrier of height \begin{math} \Delta V \end{math} is increased by a factor of approximately \begin{math} e^{\Delta V} \end{math}, for large values of \begin{math} \Delta V \end{math}. This relationship is depicted graphically in Fig.~\ref{fig:quantum_advantage} which shows the probability of barrier traversal for a system which allows quantum fluctuations, divided by the same probability for a system which only considers thermal fluctuations. Fig.~\ref{fig:quantum_advantage} illustrates the fact that physical models which considers quantum effects are much more likely to predict penetration of tall, thin energy barriers than those which only include classical thermal effects. 
	 
	 The general probability density function for the Cauchy distribution k is given by	
	 \begin{equation*}
	 g_C(x) = \frac{1}{\pi\gamma}\frac{\gamma^2}{(x-x_0)^2 - \gamma^2}
	 \end{equation*}
	 \noindent where $x_0$ is the mean and $\gamma$ is a shape parameter. In this work, $\gamma$ will always be set to $1$ and the mean will always be $0$, yielding the specific Cauchy distribution given by
	 
	  \begin{equation}
	  g_C(x) = \frac{1}{\pi x^2 -\pi}.
	  \label{eq:cauchy_pdf}
	  \end{equation}
	  
	  
	
	 

	

	\subsubsection{Generalized Simulated Annealing Visiting Distribution}
	
	The most sophisticated form of SA is GSA, described by Tsallis and Stariolo in \cite{tsallis1996generalizedsimulatedannealing}. As the name implies, this SA implementation is a generalization of other forms of SA, specifically CSA and FSA, which can be recovered under certain conditions in the GSA formulation. As with FSA, GSA is essentially SA with a modified visiting distribution. The visiting distribution proposed in \cite{tsallis1996generalizedsimulatedannealing} is given by 
	
	\begin{align}\label{eq:gsa_visiting_distribution}
		g_{GSA}(x) = \left[ \left(\frac{q_V-1}{\pi}\right)^{(D/2)} \right]
		\left[ \frac{\Gamma \left( \frac{1}{q_V-1}+\frac{D-1}{2} \right) }{\Gamma \left( \frac{1}{q_V-1}-\frac{1}{2} \right)} \right]
		\left[ \frac{T_{q_V}^{-\frac{D}{3-q_V}}}{\left( 1+\frac{(q_V-1)(x^2)}{\left(T_{q_V}^{2(3-q_V)}\right)}\right)^{\frac{1}{q_V-1}+\frac{D-1}{2}} } \right].
	\end{align}
	
	\noindent where $D$ is the dimensionality of the solution space to be searched, $q_V$ is a free parameter which is selected by the experimenter, and $T_{q_V}$ is an introduced stochastic process control parameter\footnote{This temperature parameter is completely independent from the annealing temperature parameter of SA. The two parameters can vary independently of on another, but will both be annealed over the course of the algorithm.} which may, or may not, change during the execution of the SA algorithm. Unlike the Cauchy and Gaussian visiting distributions used in CSA and FSA, the GSA visiting distribution has several free parameters which alter the shape and scale of the distribution. The GSA visiting distribution should therefore be conceptualized as a family of related distributions, from which one may be selected to construct a GSA neighborhood function. 
	
	Fig.~\ref{fig:gsa_distribution} contains a comparison between the distributions produced by several variations of $q_V$ and $T_{q_V}$, with $D$ set to $1$. Values of $q_V$ which are near $1$ yield very light-tailed distributions, which are similar to Gaussian distributions. As $q_V \rightarrow 1$, $g_{GSA}(x)$ recovers $g_{G}(x)$. Similarly, as $q_V \rightarrow 2$, $g_{GSA}(x)$ recovers the Cauchy distribution, $g_{C}(x)$; this behavior is seen in the $q_V=2$, $T_{q_V}=1$ case displayed Fig.~\ref{fig:gsa_distribution}, in which the GSA distribution exactly recovers the Cauchy distribution. Values of $q_V$ greater than $2$ do not have a independent analog distribution and have been experimentally shown [bunch of cites here] to yield more efficient SA algorithms, when used as a visiting distribution. 	
	
	\begin{figure}[ht!]
		
		%\vspace{-0.5cm}
		\centerline{\includegraphics[width = 5in]{figures/gsa_distributions.png}}
		\caption{This figure comprises four plots, each of which displays a GSA distribution at various values of $T_{q_V}$, in order to illustrate the behavior of the GSA distribution for several values of $q_V$. This figure shows the GSA near the mean, which illustrates the effect of $q_v$ and $T_{q_V}$ on the near-mean domain values, while neglecting the effects on the tails of the distribution.}
		\label{fig:gsa_distribution}
		%
	\end{figure}	
	
	Several trends can be ascertained through the examination of figures \ref{fig:gsa_distribution} and \ref{fig:gsa_distribution_wing_detail}. The former displays the behavior the GSA distribution near the origin, where, for most combinations of $q_V$ and $T_{q_V}$, the majority of the probability mass is concentrated; the latter details the behavior of the GSA distribution at domain values far from the origin, or, in the tails of the distribution. As is shown in Fig.~\ref{fig:gsa_distribution}, $q_V$ primarily influences the spread of the probability mass, or shape, of the distribution. Values of $q_V$ near $1$ produce distributions which have only negligible probabilities of generating values far from the mean, while larger values increase in statistical dispersion. This behavior is particularly clear in Fig.~\ref{fig:gsa_distribution_wing_detail}, which shows the distribution over a large portion of the domain and very near the origin of the range. Examining the figure from top to bottom, in order of decreasing $q_V$, it is clear that increasing $q_V$ corresponds to an increase in the probability of a sample yielding a value far from the mean. A larger $q_V$ value also corresponds to less tail-behavior sensitivity to the temperature parameter, $T_{q_V}$. $T_{q_V}$ also influences the distribution shape. As the value of $T_{q_V}$ is increased, the distribution becomes more uniform over the domain. This has important consequences for the application of GSA distribution to stochastic search problems such as SA.
	
	\begin{figure}[ht!]
		
		%\vspace{-0.5cm}
		\centerline{\includegraphics[width = 5in]{figures/gsa_distribution_wing_detail.png}}
		\caption{This figure comprises four plots, each of which displays a GSA distribution at various values of $T_{q_V}$, in order to illustrate the behavior of the GSA distribution for several values of $q_V$. This figure shows the GSA distribution for domain values far from the mean, which illustrates the effect of $q_v$ and $T_{q_V}$ on the tails of the distribution.}
		\label{fig:gsa_distribution_wing_detail}
		%
	\end{figure}
	
	As discussed in \cite{dallinga2004performancegsa,andricioaei1996applicationgsatetrapide} the distributions produced by Eq.~\ref{eq:gsa_visiting_distribution} have several useful properties, when used in stochastic search procedures. The longer tails of the GSA distribution when $q_V>1$ enable more homogeneous visitation of the entire solution space of the problem, relative to a Cauchy distribution. Furthermore, the fact that $q_V$ is selected by the experimenter creates an opportunity for problem-specific construction of the visiting distribution used in the SA implementation. The newly-introduced temperature parameter, $T_{q_V}$, may also be exploited to escape cost surface local minima. Regardless of the value of $q_V$, large values of $T_{q_V}$ produce distributions which have high statistical dispersion, and are therefore able to produce problem configurations which far, in configuration space, from the current state. 

	While this distribution produces a neighborhood function with several advantageous search characteristics, it does have a significant drawback:  The integral of Eq.\ref{eq:gsa_visiting_distribution} has no closed-form analytic solution. The indefinite integral, but this operation yields the hypergeometric function, [function goes here], which can only be computed as a power series of increasingly complex terms. Previous work \cite{dallinga2004performancegsa} has shown that this procedure is computationally expensive. Thus, Eq.~\ref{eq:gsa_visiting_distribution} is unsuitable for the analytic inverse sampling transform method of random variable generation. In order to overcome this limitation, a distribution sample caching method was implemented. This method works by numerically approximating the integral of the distribution given by Eq.~\ref{eq:gsa_visiting_distribution}, which yields a series of domain-range value pairs which constitute a close approximation to the cumulative distribution function of the distribution. This series of values, and the displacement values to which they correspond are stored. To sample the distribution, a number is selected with uniform probability from the interval $[0,1]$. The numeric integration value which has the minimum-magnitude difference with the randomly selected value is identified, and the displacement value to which is corresponds is returned. This procedure is the numerical equivalent of inverse transform sampling. 
	
	An arbitrarily-large set of samples can be constructed using this method; If the sample set is sufficiently large, a random choice from the sample set is approximately equivalent to sampling the original distribution. A large set of samples for each combination of $q_V$, $T_{q_v}$, and $D$ can be stored for later access, thus enabling fast numerically-approximate sampling of Eq.~\ref{eq:gsa_visiting_distribution}. A system fitting this description was constructed in support of this thesis. A thorough search of the publicly-available resources indicates that there are few systems available for the generation of GSA random variables, despite the popularity and utility of GSA. As such, the GSA sample generation system constructed in support of this thesis will be made publicly-available upon publication of this thesis.
	
	
	\subsubsection{Uniform Visiting Distributions}
	
	As illustrated in Fig.~\ref{fig:quantum_tunneling} the probability of observing a particle beyond a classically-impenetrable potential barrier is uniform beyond the barrier\footnote{This observation only holds for potential energy surfaces containing a single barrier. The analogous cost surface over neural network weight space is likely to have many barriers corresponding to the superimposed convex spaces around competing conventions of weight configurations which encode similar functions. Thus the analogy used here is only an approximation of the behavior of quantum systems.}. An analogous visiting distribution can be constructed, which models all configuration space movement distances as equally likely. The utility of this visiting distribution is that it makes the entire cost surface accessible each time the neighborhood function is applied to the current state; this property is useful, but prevents any local gradient descent. As such, the uniform visiting distribution serves as a useful upper bound in the trade-space between global and local search policies. 
	

	
	\subsection{Anisotropicity Policies}
	
	In previous work, the visiting distribution is applied isotropically over the free parameters, or dimensions, of the solution space \cite{tsallis1996generalizedsimulatedannealing,dallinga2004performancegsa}. In the context of SA, isotropic application of the visiting distribution means the next state for each free parameter is a sample from a common, identical distribution. 
	
	
	\subsubsection{Isotropic Anisotropicity}
	
	
	\subsubsection{Adjacency-Based Anisotropicity}
	
	Neural networks may be views as a collection of interacting subgraphs. Each subgraph in a complete feed-forward neural network produces a 
	
	
	\subsubsection{State-Based Anisotropicity}
	
	When evaluating the traversal characteristics of the synaptic annealing algorithms constructed in the this thesis, it was observed that the sum of squared weight values grew considerably during training. Previous work \cite{} has show that large weight magnitudes result in networks with high bias, and correspondingly high generalization error. It is intuitively clear that, when using a sigmoidal activation function, a very high-magnitude weight value effectively converts the afferent neuron, relative to that synapse, into a bias. Unless an equally large-magnitude magnitude weight of opposite sign is introduced, or the weight value fluctuates to a smaller value, the afferent neuron will remain a bias. One of these contingencies may occur, but it is unlikely that such an event would reduce the total training error of the network, and is therefore likely to be rejected. In \cite{lee2007improvinggeneralizationcapabilitynnusingsa}, Lee et al. propose a method called multiobjective hybrid greedy simulated annealing (MOHGSA), which uses SA to minimize both the cost function and the sum of squared weights. By doing so, Lee et al. were able to reduce the the generalization error of a neural network trained by SA. The MOHGSA approach works by exerting a selection pressure which lowers the likelihood of the SA algorithm accepting move which reduce the cost function if they increase the sum of squared weights. 
	
	
	\section{Feed-Forward Neural Network Representation}
	\label{scn:feed_forward_neural_network_representation}
	\begin{figure}[ht!]
		
		\begin{minipage}[b]{0.48\linewidth}
			\centering
			\centerline{\epsfig{figure=figures/concrete_matrix_rep_a.eps,width=7cm}}
			%  \vspace{2.0cm}
			\centerline{(a)}\medskip
		\end{minipage}
		\hfill
		\begin{minipage}[b]{0.48\linewidth}
			\centering
			\centerline{\epsfig{figure=figures/concrete_matrix_rep_b.eps,width=7cm}}
			%  \vspace{2.0cm}
			\centerline{(b)}\medskip
		\end{minipage}
		%\vspace{-0.5cm}
		\caption{
			(a) An arbitrary feed-forward ANN.
			(b) The weight matrix representation of the feed-forward ANN in (a).}
		\label{fig:nettomatmapping}
		
	\end{figure}
	
	 The problem of feed-forward neural network synaptic weight selection must be formulated as a combinatorial optimization problem before any formulation of SA can be applied to it. Each synaptic weight in a feed-forward neural network may be encoded as a real-valued element in a 3-dimensional relation matrix, denoted as $\mathit{W}_{ijk}$. In this encoding scheme, for a given layer, $k$, of the matrix the row and column indexes indicate the presynaptic and post-synaptic neurons, respectively. The absence of a synaptic connection is indicated by a value of $0$ in the matrix element corresponding to that synaptic connection. A nonexistent synapse can be caused by the absence of either the presynaptic or post-synaptic neuron, or by the absence of a connection between the neurons. This weight encoding scheme is depicted graphically in Fig.~\ref{fig:nettomatmapping}. The weight matrix, $\boldsymbol{\mathcal{W}}$, therefore encodes a configuration in the solution space of the problem, and can be visualized as:
	 
	 \begin{figure}[ht!]
	 	\begin{center}
	 		\includegraphics[width = 2.1in]{figures/abstract_matrix_rep.eps}
	 		\label{fig:abstract_matrix_rep}
	 	\end{center}
	 \end{figure}
	 
	 \noindent The total solution space, $\boldsymbol{\mathcal{S}}$, may then be defined as the set of all possible configurations of $\boldsymbol{\mathcal{W}}$ for a given neural network. $\boldsymbol{\mathcal{W}}$ is, in effect, the phase space of the feed-forward neural network system. In the synaptic weight selection problem domain it is more evocative to call $\boldsymbol{\mathcal{S}}$ the weight space of the network, so this convention adopted throughout this thesis. Given $\boldsymbol{\mathcal{S}}$, we define a cost function $ \mathcal{C}$ to be the mapping
	 
	 \begin{equation*} \label{eq:cost_mapping_ffnn}
	 \mathcal{C} : \boldsymbol{\mathcal{S}} \rightarrow \mathbb{R}.
	 \end{equation*}
	 
	 
	 Each possible synaptic weight configuration of $\boldsymbol{\mathcal{W}}$ then corresponds to some cost value $\mathcal{C}(\boldsymbol{\mathcal{W}})$. Thus $\mathcal{C}(\boldsymbol{\mathcal{W}})$ defines a cost surface embedded in the weight space. The objective is now to find a synaptic weight configuration, $\boldsymbol{\mathcal{W}_{opt}}$ such that 
	 
	 \begin{equation*} \label{eq:optimal_definition}
	 \mathcal{C}(\boldsymbol{\mathcal{W}}_{opt}) \leq \mathcal{C}\left( \boldsymbol{\mathcal{W}}\right) , \forall\left(  \boldsymbol{\mathcal{W}} \in \boldsymbol{\mathcal{S}}\right) .
	 \end{equation*}
	 
	 \noindent With this framework in place, the SA can be applied to transition from a randomly-selected initial state, $\boldsymbol{\mathcal{W}}_0$, to $\boldsymbol{\mathcal{W}}_{opt}$. In this thesis all weights were initialized to a value drawn from a uniform distribution over the range $[-0.1,0.1]$.
	 

	\section{Applying Simulated Annealing to Feed-Forward Neural Network Weight Modification}
	
	The formulations of SA described in Sec.~\ref{scn:simulated_annealing} may be applied to any properly formulated combinatorial optimization problem. The representation formalism for the weight parameters of a feed forward neural network presented in Sec.~\ref{scn:feed_forward_neural_network_representation} can serve as the parameter space in a combinatorial optimization function, and thus enables the application of SA to the problem of neural network weight selection. With a more concrete problem definition in place, it is now possible to precisely specify several SA neighborhood functions for the problem of neural network weight selection. In the following sections, several complete definitions of neighborhood functions are presented for the application of SA to feed-forward neural networks. The term \textit{synaptic annealing} is introduced to represent any artificial neural network training algorithm which modifies synaptic weights using SA.
	
	
	\subsection{Synaptic Annealing Neighborhood Functions}
	\label{scn:classical_neighborhood}
	
	A generic synaptic annealing neighborhood function may be defined as
	\begin{align}\label{eq:generic_anisotropic_neighborhood}
	\mathcal{N} (\boldsymbol{\mathcal{W}}) = \boldsymbol{\mathcal{W}} + \alpha (\boldsymbol{G} \circ\boldsymbol{\mathcal{A}})
	\end{align}
	\noindent where $\alpha$ is the learn rate parameter, $\boldsymbol{G}$ is the neighborhood sample matrix, and $\boldsymbol{\mathcal{A}}$ is the anisotropicity matrix.\footnote{The symbol $\circ$ denotes the Hadamard product operation, which is simply the element-wise product of two matrices.} Each element in the neighborhood sample matrix, $\boldsymbol{G}$, is a sample generated using the random variable generation function ${G}^{-1}(U)$, where ${G}^{-1}$ is the sample generation function for a visiting distribution $g(x)$, and $U$ is a uniform random variable over the range $[0,1]$. Generally, ${G}^{-1}$ is the inverse transform of the cumulative distribution function of the visiting distribution, or a numeric approximation thereto. Both $\boldsymbol{G}$ and $\boldsymbol{\mathcal{A}}$ have dimensionality equal to that of $\boldsymbol{\mathcal{W}}$. Additionally, the following constraint is imposed on the matrices:\begin{align}\label{eq:perturbation_temp_matrix_constraints}
	\forall \; \mathcal{W}_{i,j,k} \in \boldsymbol{\mathcal{W}},  [\mathcal{W}_{i,j,k}=0] \rightarrow [\boldsymbol{\mathcal{A}}_{i,j,k}=0] \wedge [\boldsymbol{G}_{i,j,k}=0].
	\end{align}
	\noindent The constraint specified in Eq.~\ref{eq:perturbation_temp_matrix_constraints} ensures that synaptic connections which are not specified to exist, and are therefore set to exactly $0$, are not inadvertently created by the neighborhood function.\footnote{Strictly speaking, it is possible for a weight to be set to exactly $0$ in the normal operation of the SA algorthim. If this were to occur, the constraint specified in Eq.~\ref{eq:perturbation_temp_matrix_constraints} would prevent that weight from ever being modified again. This scenario was never observed in the course of this work, and is very unlikely, but is not explicitly forbidden by the implementation of synaptic annealing proposed in this work.} The term $\alpha (\boldsymbol{G} \circ\boldsymbol{\mathcal{A}})$ in Eq.~\ref{eq:generic_anisotropic_neighborhood} is added to the current weight matrix to produce a new weight matrix, and can therefore be thought of as a perturbation of the current state. In the following sections several realizations of this general form, each corresponding to a different form of SA, are presented.
	
	\subsubsection{Gaussian (CSA) Synaptic Annealing Neighborhood}
	
	The original description of SA employed a Gaussian visiting distribution \cite{kirkpatrick1983}. The Gaussian neighborhood function for feed-forward neural networks, \begin{math}\mathcal{N}_{g}\end{math}, is defined as \begin{align}\label{eq:gaussian_neighborhood}
	\mathcal{N}_{G} (\boldsymbol{\mathcal{W}}) =  \boldsymbol{\mathcal{W}} + \alpha (\boldsymbol{G}_G  \circ\boldsymbol{\mathcal{A}})
	\end{align}
	\noindent where $\alpha$ is the learning rate, $\boldsymbol{G}_g$ a matrix of samples drawn from the standard normal distribution, and $\boldsymbol{\mathcal{A}}$ is an anisotropicity matrix.
	
	
	The neighborhood function given in Eq.~\ref{eq:gaussian_neighborhood} is an application of the canonical form of simulated annealing to the problem of selecting a weight configuration for a feed-forward neural network. The term classical is used here because the underlying simulated annealing model can be described entirely in terms of classical statistical mechanics. To interpret this in terms of the analogy present in Sec.~\ref{scn:visiting_distributions}, the probability of the Gaussian visiting distribution used in CSA generating a weight space distance large enough to transition the system across a large energy barrier is effectively $0$. In the following sections, models which approximate quantum mechanical phenomena will be constructed.
	
	\subsubsection{Cauchy (FSA) Synaptic Annealing Neighborhood}
	
	\subsubsection{Tsallis (GSA) Synaptic Annealing Neighborhood}
	
	
	... The generation of samples from this distribution is troublesome because it involves the inversion of a power series. Thus in support of this thesis, a novel library was developed from efficiently generating numeric approximations of GSA distribution samples.
	
	\subsubsection{Uniform Synaptic Annealing Neighborhood}

	Imagine simulated annealing as a genetic algorithm with a generation size of one. It is clear that the neighborhood function corresponds to the mutation function in this analogy. 
	
	
	
	\subsection{Feed-Forward Neural Network Anisotropicity Policies}
	\label{scn:ffnn_anisotropicity}
	In the course of developing the synaptic weight selection system presented in this thesis, it was observed that it is sometimes advantageous to apply different distributions to different synaptic weights. 
	
	
	\section{Weight Space Traversal}
	
	In SA, the purpose of the neighborhood function is to control the traversal of the solution space of the problem. For synaptic annealing the solution space is the synaptic weight space, thus synaptic annealing neighborhood functions control the algorithms traversal of the weight space. The performance of a neighborhood function is entirely dictated by the weight space traversal, or walk, that it produces. In order to characterize the traversal properties of each neighborhood function, a traversal through a two-dimensional subset of the weight space will be analyzed for each neighborhood function. A small feed-forward neural network, with two input neurons, two hidden layer neurons, and a single output layer neuron, will be trained using synaptic annealing to solve a simple functional approximation problem. The function to be approximated is the complex-interaction function used in \cite{lee2007improvinggeneralizationcapabilitynnusingsa}, which is given by \begin{equation}
	f_{CI}(u_1,u_2) = 1.9(1.35 + e^{0.5(u_1+1)} \sin ( 13 (0.5 u_1 - 0.1 )^2 ) · e^{−0.5(u_2+1)} \sin(3.5u_2 + 3.5)).
	\end{equation}
	The synaptic annealing algorithm will attempt to minimize the mean-squared error (MSE) cost function, as defined in section \ref{scn:cost_functions}, on $100$ randomly-drawn samples of $f_{CI}$. The validation error of the syanatic annealing algorithm will also be evaluated using an addition $100$ randomly drawn samples, which are not presented to the algorithm during training. The same validation and training samples will be used for the analysis of each neighborhood functions traversal.  This section contains an analysis of the the weight space traversal properties of synaptic annealing during a relatively short training period. A more thorough analysis of the performance of synaptic annealing on this problem is presented in Chapter \ref{ch:results}. For each neighborhood function, the traversal through the $W_{1,1,1}$-$W_{2,2,1}$ space is analyzed. $W_{1,1,1}$ is the synaptic weight from input neuron $1$ to hidden neuron $1$, while $W_{2,2,1}$ is the synaptic weight from input neuron $2$ to hidden neuron $2$. The weight space traversal behavior of the algorithm was empirically found to be independent of the specific choice of weights.
	
	
	

	\subsection{Gaussian Neighborhood Function Weight Space Traversal} 
	
	0.1817206687082039 0.2350612776255982
	
	The weight 
 	\begin{figure}[ht!]
 		
 		\begin{minipage}[b]{0.5\linewidth}
 			\centering
 			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_gaussian.png}}
 			%  \vspace{2.0cm}
 			\centerline{(a)}\medskip
 		\end{minipage}
 		\hfill
 		\begin{minipage}[b]{0.5\linewidth}
 			\centering
 			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_gaussian_perf.png}}
 			%  \vspace{2.0cm}
 			\centerline{(b)}\medskip
 		\end{minipage}
 		%\vspace{-0.5cm}
 		\caption{
 			(a) A plot showing the traversal of the $w_1,w_2$ subspace of the weight space over the course of $3,000$ epochs produced by a synaptic annealing algorithm employing a Gaussian visiting distribution. A solid line indicates a move which was accepted by the simulate annealing algorithm, while a dashed line indicates a move which was rejected. In this figure, only a few rejected moves are visible. The word $start$ indicates the initial value of $(w_1,w_2)$, while the word $end$ denotes the final value. 
 			(b) (upper) A plot showing the both the training and validation MSE of the results produced by the neural network in each epoch. This is the post-perturbation error, meaning that the error associated with moves that were rejected is shown. (lower) A plot showing the sum of squared weights of the neural network during each training epoch.}
 		\label{fig:weight_space_gaussian}
 		
 	\end{figure}
	 
	\subsection{Cauchy Neighborhood Function Weight Space Traversal} 
	0.1530194184840675 0.947064498907736

	 
  	\begin{figure}[ht!]
  		
  		\begin{minipage}[b]{0.5\linewidth}
  			\centering
  			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_cauchy.png}}
  			%  \vspace{2.0cm}
 			\centerline{(a)}\medskip
  		\end{minipage}
  		\hfill
  		\begin{minipage}[b]{0.5\linewidth}
  			\centering
  			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_cauchy_perf.png}}
  			%  \vspace{2.0cm}
  			\centerline{(b)}\medskip
  		\end{minipage}
  		%\vspace{-0.5cm}
  		\caption{
  			(a) A plot showing the traversal of the $w_1,w_2$ subspace of the weight space over the course of $3,000$ epochs produced by a synaptic annealing algorithm employing a Cauchy visiting distribution. A solid line indicates a move which was accepted by the simulate annealing algorithm, while a dashed line indicates a move which was rejected. In this figure, only a few rejected moves are visible. The word $start$ indicates the initial value of $(w_1,w_2)$, while the word $end$ denotes the final value. 
  			(b) (upper) A plot showing the both the training and validation MSE of the results produced by the neural network in each epoch. This is the post-perturbation error, meaning that the error associated with moves that were rejected is shown. (lower) A plot showing the sum of squared weights of the neural network during each training epoch.}
  		\label{fig:weight_space_cauchy}
  		
  	\end{figure}

	\subsection{GSA Neighborhood Function Weight Space Traversal} 
	0.047256769936850254 0.2327393711292716
	Observation reveals that these simultaneous training error decreases and validation error increases coincide with la

	 
   	\begin{figure}[ht!]
   		
   		\begin{minipage}[b]{0.5\linewidth}
   			\centering
   			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_gsa_i.png}}
   			%  \vspace{2.0cm}
   			\centerline{(a)}\medskip
   		\end{minipage}
   		\hfill
   		\begin{minipage}[b]{0.5\linewidth}
   			\centering
   			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_gsa_i_perf.png}}
   			%  \vspace{2.0cm}
   			\centerline{(b)}\medskip
   		\end{minipage}
   		%\vspace{-0.5cm}
   		\caption{
   			(a) A plot showing the traversal of the $w_1,w_2$ subspace of the weight space over the course of $3,000$ epochs produced by a synaptic annealing algorithm employing an isotropic GSA visiting distribution. A solid line indicates a move which was accepted by the simulate annealing algorithm, while a dashed line indicates a move which was rejected. In this figure, only a few rejected moves are visible. The word $start$ indicates the initial value of $(w_1,w_2)$, while the word $end$ denotes the final value. 
   			(b) (upper) A plot showing the both the training and validation MSE of the results produced by the neural network in each epoch. This is the post-perturbation error, meaning that the error associated with moves that were rejected is shown. (lower) A plot showing the sum of squared weights of the neural network during each training epoch.}
   		\label{fig:weight_space_gsa_i}
   		
   	\end{figure}
	   	
	
	\subsection{Uniform Neighborhood Function Weight Space Traversal} 
	
	0.06475156493279362 0.3967557372842911

	 
   	\begin{figure}[ht!]
   		
   		\begin{minipage}[b]{0.5\linewidth}
   			\centering
   			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_uniform.png}}
   			%  \vspace{2.0cm}
   			\centerline{(a)}\medskip
   		\end{minipage}
   		\hfill
   		\begin{minipage}[b]{0.5\linewidth}
   			\centering
   			\centerline{\includegraphics[width = 3.25in]{figures/weight_space_uniform_perf.png}}
   			%  \vspace{2.0cm}
   			\centerline{(b)}\medskip
   		\end{minipage}
   		%\vspace{-0.5cm}
   		\caption{(a) A plot showing the traversal of the $(w_1,w_2)$ subspace of the weight space over the course of $3,000$ epochs produced by a synaptic annealing algorithm employing a visiting distribution which is uniform over the rang $[-2,2]$. A solid line indicates a move which was accepted by the simulate annealing algorithm, while a dashed line indicates a move which was rejected. In this figure, only a few rejected moves are visible. The word $start$ indicates the initial value of $(w_1,w_2)$, while the word $end$ denotes the final value. (b) (upper) A plot showing the both the training and validation MSE of the results produced by the neural network in each epoch. This is the post-perturbation error, meaning that the error associated with moves that were rejected is shown. (lower) A plot showing the sum of squared weights of the neural network during each training epoch.}
   		\label{fig:weight_space_uniform}
   		
   	\end{figure}
   	
	
	
	%[Plot: squared sum of weighs along X, training and validation error along Y]
	%[Plot: Training Epoch along X, sum of squared weights the neighborhood function sa on Y]
	
	%[The GSA neighborhood function outperforms the gaussian and cauchy distribution in training error, but under performs in generalization error. This performance dynamic may be explained by the fact that ]
	
	

	\section{Cost Functions}
	\label{scn:cost_functions}
	All variations of SA require the specification of a heuristic cost function. 
	
	In synaptic annealing, unlike back-propigation, there is no explicit gradient-following. As such, there is no 
	
	%[still need to explore STUN cost function with new ly-corrected regression error.]
	%[Still need to evaluate the performance using a smaller network... do this when at home]
	%[might depend on cost function... Try making it smaller first with regression]
	%[if classification error is really good with a large network be not with a small network, that's a paragraph in results.]
	
	\section{Design of Experiments}
	
	% DO: Rework entire results section.
	
	\chapter{Results}
	\label{ch:results}
	
%	Is my algorithm computationally efficient as in Haykin, pg 229?
	\makeatletter
	\def\fixedlabel#1#2{%
		\@bsphack%
		\protected@write\@auxout{}%
		{\string\newlabel{#1}{{#2}{\thepage}}}%
		\@esphack}
	\makeatother
	
	\begin{figure*}[ht!]
		\centering
		\setlength{\tabcolsep}{-3pt}
		\begin{tabular}{c@{}cccc}
			& Gaussian & Exponential & Cauchy & Uniform \\
			
			\rotatebox{90}{Isotropic }
			& \includegraphics[width = 1.8in, trim={0.5cm 0 1.3cm 0.8cm},clip]{figures/classPerf/classPerf_GaussianVisit_IsotropicAnisotropicity.png} \fixedlabel{block1a}{1a} 	
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_ExponentialVisit_IsotropicAnisotropicity.png} \fixedlabel{block1b}{1b} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_CauchyVisit_IsotropicAnisotropicity.png} \fixedlabel{block1c}{1c} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_UniformVisit_IsotropicAnisotropicity.png} \fixedlabel{block1d}{1d} \\ \\[-10pt]
			
			
			\rotatebox{90}{	\begin{tabular}[x]{@{}c@{} }   Uniform \\ Anisotropicity \end{tabular} }
			& \includegraphics[width = 1.8in, trim={0.5cm 0 1.3cm 0.8cm},clip]{figures/classPerf/classPerf_GaussianVisit_UniformAnisotropicity.png} \fixedlabel{block2a}{2a} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_ExponentialVisit_UniformAnisotropicity.png} \fixedlabel{block1b}{2b} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_CauchyVisit_UniformAnisotropicity.png} \fixedlabel{block1b}{2c} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_UniformVisit_UniformAnisotropicity.png} \fixedlabel{block2b}{2d} \\ \\[-10pt]
			
			\rotatebox{90}{	\begin{tabular}[x]{@{}c@{}} Variable \\ Anisotropicity \end{tabular}	}
			& \includegraphics[width = 1.8in, trim={0.5cm 0 1.3cm 0.8cm},clip]{figures/classPerf/classPerf_GaussianVisit_NormativeAnisotropicity.png}\fixedlabel{block3a}{3a} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_ExponentialVisit_NormativeAnisotropicity.png}\fixedlabel{block1b}{3b} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_CauchyVisit_NormativeAnisotropicity.png}\fixedlabel{block1b}{3c} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/classPerf/classPerf_UniformVisit_NormativeAnisotropicity.png}\fixedlabel{block3b}{3d}
			
		\end{tabular}
		\caption{The simulation-time evolution of the 25-fold cross-validated classification error of a feed-forward neural network with 50 hidden units on Fishers iris data. Each column in this table depicts the results for an SA neighborhood function employing a single type of visiting distribution, which is indicated in the column header. Each row depicts a single type of anisotropicity strategy, which is indicated in the row header. The classification error is defined as the fraction of samples incorrectly classified.}
		
		\label{fig:class_perf}
		
	\end{figure*}
	
	
	In this section several experiments are presented to evaluate the performance of the annealing procedures defined in the Sec.~\ref{scn:problem_formulation}.
	
	
	\subsection{Classification Performance}
	
	We begin by evaluating the impact of neighborhood function choice on the classification performance of a feed-forward neural network trained by SA. Fig.~\ref{fig:class_perf} contains the simulation-time evolution of classification performance for a feed-forward neural network with 50 hidden units in a single hidden layer. This performance data was generated by a neural network trained to classify Fishers iris data, which comprises $150$ samples with input dimensions and $3$ class labels. Before training on the data, it is normalized, shuffled and the mean is removed.
	
	Each experiment, which consists of the evaluation of a single neighborhood function, is performed using 25-fold cross validation. The results presented in Fig.~\ref{fig:class_perf} are the time evolution of the mean training and validation set classification error. All results are presented up to the $500,000$\textsuperscript{th} training epoch. Each training epoch evaluates the entire training and validation set when producing the classification error.
	
	
	\subsubsection{Visiting Distribution Analysis}
	
	The classification performance of CSA, which is defined by an isotropic application of a Gaussian generating function, is displayed in the top-left tile of \ref{fig:class_perf}. We see that 25-fold cross validated perfect classification is achieved at approximate $400,000$ epochs. That is, all 25 of the independent SA trials had achieved perfect classification at or before epoch $400,000$. Comparing the only the performance of the isotropic anisotropicity neighborhood functions we find that the Cauchy visiting distribution converged slightly faster than the Gaussian on the training set, but takes slightly longer to correctly generalize to the validation set. This is somewhat unexpected, as FSA is generally much faster than CSA. The exponential visiting distribution performs poorly relative to both CSA and FSA, but this is not surprising. Though the exponential distribution is in close analogy to the physics of quantum tunneling it is a very light-tailed function, and as such is unlikely to produce neighbors far from the current configuration. As such, it appears to be unable traverse the error surface as quickly. Finally, we find that the worst performing visiting distribution is the uniform distribution. The uniform visiting distribution amounts to a random global search of the weight space; the weight space for this problem is $350$-dimensional, so finding the global minimum of the space by chance is unlikely. These performance relationships between visiting distribution hold for all anisotropicity strategies, with the notable exception of uniform visiting distributions with variable annealing, which is discussed in Sec.~\ref{scn:anisotropicity_analysis}
	
	\subsubsection{Anisotropicity Analysis}
	\label{scn:anisotropicity_analysis}
	
	Observing figs.~\ref{fig:class_perf} and \ref{fig:perfect_class_time} we see that neighborhood functions implementing uniform anisotropicity consistently outperform those which use isotropic weight change assignment. Further, we find that while variable anisotropicity confers no advantage on either CSA or FSA, it significantly improves the performance of the two non-canonical simulated annealing visiting distributions. With variable anisotropicity, both the exponential and uniform distribution outperform CSA and FSA. One of the most striking results depicted in Fig.~\ref{fig:perfect_class_time} is the interaction effect of a uniform visiting distribution and a variable anisotropicity matrix, visible in the bottom-right corner of the figure. While both the uniform visiting distribution and the variable anisotropicity under-perform relative to their alternatives, when combined the make for the most effective neighborhood function considered in this paper. This interaction effect is likely due to the specificity of modification afforded by the combination of a highly anisotropic modification and a global search reach. We should expect that for very large networks this advantage would diminish somewhat, as the global search space would be much larger. Further study is needed to evaluate the potential general applicability of this neighborhood function.
	
	
	\begin{figure*}
		\label{fig:perfect_class_time}
		\centering
		\setlength{\tabcolsep}{-3pt}
		\begin{tabular}{c@{}cccc}
			& Gaussian & Exponential & Cauchy & Uniform \\
			
			\rotatebox{90}{Isotropic }
			& \includegraphics[width = 1.8in, trim={0.5cm 0 1.3cm 0.8cm},clip]{figures/completeFrac/completeFrac_GaussianVisit_IsotropicAnisotropicity.png} \fixedlabel{block1a}{1a} 	
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_ExponentialVisit_IsotropicAnisotropicity.png} \fixedlabel{block1b}{1b} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_CauchyVisit_IsotropicAnisotropicity.png} \fixedlabel{block1c}{1c} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_UniformVisit_IsotropicAnisotropicity.png} \fixedlabel{block1d}{1d} \\ \\[-10pt]
			
			
			\rotatebox{90}{	\begin{tabular}[x]{@{}c@{} }   Uniform \\ Anisotropicity \end{tabular} }
			& \includegraphics[width = 1.8in, trim={0.5cm 0 1.3cm 0.8cm},clip]{figures/completeFrac/completeFrac_GaussianVisit_UniformAnisotropicity.png} \fixedlabel{block2a}{2a} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_ExponentialVisit_UniformAnisotropicity.png} \fixedlabel{block1b}{2b} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_CauchyVisit_UniformAnisotropicity.png} \fixedlabel{block1b}{2c} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_UniformVisit_UniformAnisotropicity.png} \fixedlabel{block2b}{2d} \\ \\[-10pt]
			
			\rotatebox{90}{	\begin{tabular}[x]{@{}c@{}} Variable \\ Anisotropicity \end{tabular}	}
			& \includegraphics[width = 1.8in, trim={0.5cm 0 1.3cm 0.8cm},clip]{figures/completeFrac/completeFrac_GaussianVisit_NormativeAnisotropicity.png}\fixedlabel{block3a}{3a} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_ExponentialVisit_NormativeAnisotropicity.png}\fixedlabel{block1b}{3b} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_CauchyVisit_NormativeAnisotropicity.png}\fixedlabel{block1b}{3c} 
			& \includegraphics[width = 1.6in, trim={2.35cm 0 1.5cm 0.8cm},clip]{figures/completeFrac/completeFrac_UniformVisit_NormativeAnisotropicity.png}\fixedlabel{block3b}{3d}
			
		\end{tabular}
		\caption{The simulation-time evolution of the fraction of 25 independent simulated annealing runs achieving perfect classification of Fishers iris data using a feed-forward neural network with 50 hidden units. Columns and rows are labeled as in Fig.~\ref{fig:class_perf}.}
	\end{figure*}
	
	
	\subsubsection{Perfect Classification Rate Analysis}
	
	It is not possible to analyze the classification performance of individual SA trials in Fig.~\ref{fig:class_perf} because the classification performance is averaged. In order to analyze the performance of the individual trials more thoroughly Fig.~\ref{fig:perfect_class_time} shows the fraction of the 25 independent SA trails that have completed at each training epoch. The relative performance of the neighborhood functions are similar when compared using this metric, but we can gain additional insight from the new data. The fractional-completion data shows us that for almost all of the neighborhood functions the relationship between the simulation time and the fraction of trials achieving perfect classification is not linear. Instead, the relationship resembles a Gamma distribution cumulative distribution function. As such, we take the expectation value and standard deviation of the time required to reach a cost surface global minimum and use these values to complete the shape and scale parameters of the Gamma distribution. With the shape and scale parameters, it is possible to reconstruct the probability density function which approximates the PDF of the time to perfect classification.
	
	
	These PDFs are useful because they can inform an important annealing technique: reannealing. As an annealing network traverses a cost surface it is possible for the system to become temporarily trapped in a basin which is far, in weight space distance, from the global minimum. As such, it is occasionally useful to increase, or rescale, the stochastic control parameters. It is suggested in \cite{ingber1989veryfastsimulatedreannealing} that the temperature be rescaled at approximately every hundred successful jumps. Though no reannealing schedule is presented in this paper, Figs.~\ref{fig:gaussian_gamma}, \ref{fig:exp_gamma}, \ref{fig:uniform_gamma}, and \ref{fig:cauchy_gamma} provide information regarding the optimal rescaling frequency for this classification problem. We suggest that the temperature rescaling interval which minimizes the average time required to reach a global minimum is the time at which the first inflection point of the perfect classification time PDF occurs. This choice of rescaling interval would ensure that the system constantly remains in the phase of the annealing process during which it has the greatest probability per unit time to reach a global minimum of the cost surface. This point corresponds to the expected value of the time to find the global minimum.
	
	\begin{figure} 
		\includegraphics[width = 3.3in, trim={0.5cm 0 1.2cm 0.0cm},clip]{figures/gammaDists/gamma_g.png}
		\caption{This figure shows the gamma distribution approximations of the probability of achieving perfect classification through simulation time. This figure depicts the approximations for all Gaussian visiting distributions, and thus corresponds to the first column of Fig.~\ref{fig:perfect_class_time}}
		\label{fig:gaussian_gamma}
	\end{figure}
	
	\begin{figure} 
		\includegraphics[width = 3.3in, trim={0.5cm 0 1.2cm 0.0cm},clip]{figures/gammaDists/gamma_e.png}
		\caption{This figure shows the gamma distribution approximations of the probability of achieving perfect classification through simulation time. This figure depicts the approximations for all  exponential visiting distributions, and thus corresponds to the second column of Fig.~\ref{fig:perfect_class_time}}
		\label{fig:exp_gamma}
	\end{figure}
	
	\begin{figure} 
		\includegraphics[width = 3.3in, trim={0.5cm 0 1.2cm 0.0cm},clip]{figures/gammaDists/gamma_u.png}
		\caption{This figure shows the gamma distribution approximations of the probability of achieving perfect classification through simulation time. This figure depicts the approximations for all uniform visiting distributions, and thus corresponds to the third column of Fig.~\ref{fig:perfect_class_time}}
		\label{fig:uniform_gamma}
	\end{figure}
	
	\begin{figure} 
		\includegraphics[width = 3.3in, trim={0.5cm 0 1.2cm 0.0cm},clip]{figures/gammaDists/gamma_c.png}
		\caption{This figure shows the gamma distribution approximations of the probability of achieving perfect classification through simulation time. This figure depicts the approximations for all Cauchy visiting distributions, and thus corresponds to the fourth column of Fig.~\ref{fig:perfect_class_time}}
		\label{fig:cauchy_gamma}
	\end{figure}
	
	
	\section{Conclusion}
	
	We have proposed anisotropicity as a new simulated annealing neighborhood function parameter, presented a framework for applying simulated annealing to feed forward neural network weight selection, and numerically analyzed the performance of annealing systems constructed according to this framework. We have demonstrated that the anisotropicity of a neighborhood function can have a significant impact on the classification performance of a feed forward neural network.  
	
	An exploratory study of oscillatory variation in the distribution temperature parameter of the SGSA distribution yielded encouraging preliminary results. Further study may yield additional insights into the benefits of alternating global and local distribution characteristics during a semi-local solution space search.
	
	\label{scn:conclusion}
	\appendix		% Appendix begins here
	
	\chapter{First appendix title}
	
	\section{In an appendix} 
	
	This is appendix section A.1.
	
	Note: I highly recommend you create each chapter in a separate file
	including the \verb|\chapter| command and \verb|\include| the file.
	Then you can use \verb|\includeonly| to process selected chapters and
	you avoid having to latex/preview/print your entire document every
	time.
	
	%\begin{Bibliography}	     % CAUTION: the first B is capital B.
	%\bibitem[key] A listing ... % You can also use the `thebibliography'
	%\bibitem[key2] A another    % environment described in LaTeX manual.
	%\bibitem[key3]...	     % The usages of \bibitem and \cite{..} are
	%\end{Bibliography}          % explained in Section 4.3 of the LaTeX manual.
	
	% you can also use BibTeX instead of the above as I have done below. 
	% see the LaTeX manual and the
	% documentation available from /usr/TeX/doc.  There is an AFIT 
	% bibliography style called thesnumb.  It has some special types 
	% and fields.  See some sample entries and info in thesnumb.doc.  
	% Note: thisthesis bibliography style only works with bibtex 
	% version .99a or higher.
	
	\bibliographystyle{thesnumb}
	\bibliography{synapticAnnealingBib}
	
	\begin{vita}
		Insert your brief biographical sketch here. Your permanent
		address is generated automatically.
	\end{vita}
	
	%\begin{vita} %uncomment for twoauthor option
	%	The second vita.
	%	Insert the second authors brief biographical sketch here. 
	%\end{vita}
	
\end{document}

% Please mail your suggestions and complaints to jdyoung@afit.af.mil.
